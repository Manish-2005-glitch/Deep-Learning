{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36fec144-7af9-4db3-ace5-df94529af30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0f99e7a-6c57-4c59-819b-20dd71161b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'utkface_aligned_cropped/UTKFace/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2635be4f-5af4-45da-a818-186ff6cd6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "age=[]\n",
    "gender=[]\n",
    "img_path=[]\n",
    "for file in os.listdir(folder_path):\n",
    "  age.append(int(file.split('_')[0]))\n",
    "  gender.append(int(file.split('_')[1]))\n",
    "  img_path.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3497b76-e5b1-43d1-a603-f7786b456e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23708"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff31cf94-5b1e-4353-abb9-d29d3377090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'age':age,'gender':gender,'img':img_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ac7e4f7-c938-4e8f-ac43-9dd691e97f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23708, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e17f5b87-c45b-4470-a29d-bd7affe56d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39a57957-4663-491c-8538-b50b84469088",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=1,random_state=0).iloc[:20000]\n",
    "test_df = df.sample(frac=1,random_state=0).iloc[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38619a01-ee5e-490d-a854-f9b7921e76dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85ce496f-0189-4789-95e3-eb76ac80c05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3708, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "138a66e4-c2e9-40a0-872f-f8872d14f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eefeb0ae-457e-4a43-95d4-c7a23b02376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames.\n",
      "Found 3708 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory=folder_path,\n",
    "    x_col='img',\n",
    "    y_col=['age', 'gender'],   \n",
    "    target_size=(200, 200),\n",
    "    class_mode='multi_output'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    directory=folder_path,\n",
    "    x_col='img',\n",
    "    y_col=['age', 'gender'],   \n",
    "    target_size=(200, 200),\n",
    "    class_mode='multi_output'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20d4d672-e05e-47da-8e6a-1f87ae91a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d88e3b51-cefe-4103-8b96-9a52a41d9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top=False, input_shape=(200,200,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac5023d1-56fb-490c-976f-2ff00d8ad7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.trainable=False\n",
    "\n",
    "output = resnet.layers[-1].output\n",
    "\n",
    "flatten = Flatten()(output)\n",
    "\n",
    "dense1 = Dense(512, activation='relu')(flatten)\n",
    "dense2 = Dense(512,activation='relu')(flatten)\n",
    "\n",
    "dense3 = Dense(512,activation='relu')(dense1)\n",
    "dense4 = Dense(512,activation='relu')(dense2)\n",
    "\n",
    "output1 = Dense(1,activation='linear',name='age')(dense3)\n",
    "output2 = Dense(1,activation='sigmoid',name='gender')(dense4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7513d0c1-1b0e-4092-8a1f-0c32672a9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=resnet.input,outputs=[output1,output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce6dec23-dc09-4c08-a979-785c9ddc2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss={'age': 'mae', 'gender': 'binary_crossentropy'}, metrics={'age': 'mae', 'gender': 'accuracy'},loss_weights={'age':1,'gender':99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "026d8109-91d3-4146-ab1e-7333722ef9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_output_wrapper(generator):\n",
    "    for x, y in generator:\n",
    "        yield x, tuple(y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476625f7-6c74-47af-bf04-61af5493b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    multi_output_wrapper(train_generator),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=multi_output_wrapper(test_generator),\n",
    "    validation_steps=len(test_generator)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.7",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
